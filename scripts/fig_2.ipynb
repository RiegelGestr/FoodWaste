{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def setup_mpl():\n",
    "    mpl.rc('font', size = 10)\n",
    "    mpl.rcParams['legend.fontsize'] = 'small'\n",
    "    mpl.rcParams['xtick.labelsize'] = 'small'\n",
    "    mpl.rcParams['ytick.labelsize'] = 'small'\n",
    "    #\n",
    "    mpl.rcParams['font.family'] = 'Helvetica'\n",
    "    mpl.rcParams['mathtext.default'] = 'regular'\n",
    "    #\n",
    "    mpl.rcParams['lines.linewidth'] = 1\n",
    "    mpl.rcParams['lines.markersize'] = 6  \n",
    "    mpl.rcParams['axes.linewidth'] = 0.75\n",
    "    mpl.rcParams['axes.labelpad'] = 2\n",
    "    #\n",
    "    mpl.rcParams['xtick.major.pad'] = '2.3'\n",
    "    mpl.rcParams['ytick.major.pad'] = '2.3'\n",
    "    #\n",
    "    #\n",
    "    mpl.rcParams['xtick.major.width'] = 0.75\n",
    "    mpl.rcParams['ytick.major.width'] = 0.75\n",
    "    mpl.rcParams['xtick.minor.width'] = 0.75\n",
    "    mpl.rcParams['ytick.minor.width'] = 0.75\n",
    "    #\n",
    "    mpl.rcParams['xtick.major.size'] = 3\n",
    "    mpl.rcParams['ytick.major.size'] = 3\n",
    "    #\n",
    "    mpl.rcParams['xtick.minor.size'] = 1.5\n",
    "    mpl.rcParams['ytick.minor.size'] = 1.5\n",
    "    #\n",
    "    alpha = 0.6\n",
    "    to_rgba = mpl.colors.ColorConverter().to_rgba\n",
    "setup_mpl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import community.community_louvain as louvain\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76521f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_percolation(graph,w):\n",
    "    retained_edges = [(u,v) for u,v,d in graph.edges(data = True) if d[\"weight\"] < w]\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(retained_edges)\n",
    "    components = list(nx.connected_components(G))\n",
    "    sorted_components = sorted(components, key=len, reverse=True)        \n",
    "    largest_cc_size = len(sorted_components[0]) if len(sorted_components) > 0 else 0\n",
    "    second_largest_cc_size = len(sorted_components[1]) if len(sorted_components) > 1 else 0\n",
    "    return largest_cc_size, second_largest_cc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_distance = pd.read_csv(\"../data/hdbscan_distances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_distance.index = hdbscan_distance[\"store_name\"]\n",
    "del hdbscan_distance[\"store_name\"]\n",
    "distance_long = hdbscan_distance.reset_index().melt(\n",
    "    id_vars='store_name',\n",
    "    value_name='distance',\n",
    "    var_name='node2'\n",
    ").rename(columns={'store_name': 'node1'})\n",
    "distance_long = distance_long[distance_long['node1'] != distance_long['node2']]\n",
    "distance_long['pair'] = distance_long.apply(lambda row: tuple(sorted([row['node1'], row['node2']])), axis=1)\n",
    "distance_long = distance_long.drop_duplicates(subset=\"pair\",keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca923a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gnew = nx.read_gexf(\"../data/projection_stores.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a07059",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,row in distance_long.iterrows():\n",
    "    if Gnew.has_edge(row[\"node1\"],row[\"node2\"]):\n",
    "        Gnew[row[\"node1\"]][row[\"node2\"]][\"weight\"] = row[\"distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(500, 10**6, 1_000 + 1)\n",
    "tmp_edges = []\n",
    "for bin in bins:\n",
    "    largest, second_largest = edge_percolation(Gnew,bin)\n",
    "    tmp_edges.append(\n",
    "        {\n",
    "            \"bin\":bin,\n",
    "            \"largest\":largest,\n",
    "            \"second_largest\":second_largest\n",
    "        }\n",
    "    )\n",
    "df_edges = pd.DataFrame(tmp_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5,1),dpi = 300)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(df_edges[\"bin\"],df_edges[\"largest\"]/df_edges[\"largest\"].max(),ls = \"solid\",marker = \"s\",markersize = 0,lw = 2,alpha = 0.7,color = \"firebrick\",label = \"Largest Cluster\")\n",
    "ax.plot(df_edges[\"bin\"],df_edges[\"second_largest\"]/df_edges[\"second_largest\"].max(),ls = \"dotted\",color = \"teal\",lw = 1.5,label = \"Second Largest Cluster\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"Normalized Size\")\n",
    "ax.set_xlabel(\"Distance [m]\")\n",
    "ax.axvline(26_500,color = \"silver\")\n",
    "ax.legend(\n",
    "          bbox_to_anchor=[0.5, 1.1], \n",
    "          loc='center', \n",
    "          ncol=2,\n",
    "          frameon=False)\n",
    "ax.set_xlim([1_000,100_000])\n",
    "ax.set_yticks([0.0,0.25,0.5,0.75,1.0])\n",
    "fig.savefig(\"../figure/fig_2_percolation.pdf\",bbox_inches = \"tight\",dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_colors = {\n",
    "    \"dressings\": \"#9e0142\", \n",
    "    \"patee\": \"#d53e4f\", \n",
    "    \"meat\": \"#f46d43\", \n",
    "    \"bread\": \"#fdae61\",\n",
    "    \"ham\": \"#fee08b\", \n",
    "    \"milk\": \"#ffffbf\", \n",
    "    \"desserts snacks\": \"#e6f598\", \n",
    "    \"rye breads\": \"#abdda4\",\n",
    "    \"light breads\": \"#66c2a5\",    \n",
    "    \"pork\": \"#2ca25f\",         \n",
    "    \"chicken\": \"#006d2c\",        \n",
    "    \"ready to eat meals\": \"#1C8FA6\", \n",
    "    \"cheese\": \"#2166ac\",     \n",
    "    \"yoghurt\": \"#084594\",       \n",
    "    \"sausage\": \"#5e3c99\",  \n",
    "    \"beverages\": \"#762a83\"     \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gnew = nx.read_gexf(\"../data/projection_products.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_connected_components(graph, n=1):\n",
    "    components = [graph.subgraph(c).copy() for c in nx.connected_components(graph)]\n",
    "    components_sorted = sorted(components, key=lambda x: x.number_of_nodes(), reverse=True)\n",
    "    return components_sorted[:n]\n",
    "LCC = get_largest_connected_components(Gnew)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7deeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = louvain.best_partition(LCC)\n",
    "communities = defaultdict(set)\n",
    "for node, comm in partition.items():\n",
    "    communities[comm].add(node)\n",
    "community_list = list(communities.values())\n",
    "modularity_score = nx.algorithms.community.modularity(LCC, community_list)\n",
    "bc_prods = nx.betweenness_centrality(LCC)\n",
    "df_prod_new = pd.DataFrame()\n",
    "df_prod_new[\"product\"] = bc_prods.keys()\n",
    "df_prod_new[\"bc\"] = df_prod_new[\"product\"].map(bc_prods)\n",
    "dict_prod_in_lcc = df_prod_new.groupby(by = [\"category\"]).count()[\"product\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_bc = df_prod_new[df_prod_new[\"bc\"] > df_prod_new[\"bc\"].quantile(0.9)].groupby(by = [\"category\"]).count().reset_index()\n",
    "tmp_bc[\"total\"] = tmp_bc[\"category\"].map(dict_prod_in_lcc)\n",
    "tmp_bc[\"probability\"] = tmp_bc[\"product\"]/tmp_bc[\"total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = tmp_bc.sort_values('probability', ascending=False).reset_index(drop=True)\n",
    "category_spacing = 1.0\n",
    "offset = 0.0\n",
    "x_positions = np.arange(len(df_sorted)) * category_spacing + offset\n",
    "fig = plt.figure(figsize=(3.5, 1), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i, (cat, prob) in enumerate(zip(df_sorted['category'], df_sorted['probability'])):\n",
    "    x = x_positions[i]\n",
    "    color = category_colors.get(cat, 'grey')\n",
    "    ax.vlines(x, 0, prob, color=color, linewidth=2, alpha=0.7)\n",
    "    size = 25 if prob >= 0.05 else 12.5\n",
    "    ax.scatter(x, prob, color=color, s=size)\n",
    "\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(df_sorted['category'].str.title(), rotation=45, ha='right')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylim(0,0.6)\n",
    "fig.savefig(\"../figure/fig_2_bc.pdf\",bbox_inches=\"tight\", pad_inches=0.02, dpi=300)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
